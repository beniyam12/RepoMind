# Flask + helpers
from flask import Flask, request, jsonify, send_from_directory

import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
import os
import uuid
from pathlib import Path
import io, zipfile

# ---------- App ----------
app = Flask(__name__, static_folder="static", static_url_path="/static")

# ---------- Chroma ----------
CHROMA_DIR = os.environ.get("CHROMA_DIR", "/chroma")
client = chromadb.PersistentClient(path=CHROMA_DIR)
embed_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="all-MiniLM-L6-v2"
)
collection = client.get_or_create_collection(name="docs", embedding_function=embed_fn)

# ---------- OpenAI ----------
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
oai = OpenAI(api_key=OPENAI_API_KEY)

# ---------- Chunking ----------
def chunk_by_lines(text: str, win: int = 120, overlap: int = 20):
    lines = text.splitlines()
    out = []
    i = 0
    while i < len(lines):
        j = min(len(lines), i + win)
        out.append("\n".join(lines[i:j]))
        if j == len(lines):
            break
        i = max(0, j - overlap)
    return out

def chunk_by_words(text: str, size: int = 500, overlap: int = 100):
    words = text.split()
    out = []
    i = 0
    while i < len(words):
        j = min(len(words), i + size)
        out.append(" ".join(words[i:j]))
        if j == len(words):
            break
        i = max(0, j - overlap)
    return out

def choose_chunker(filename: str):
    ext = Path(filename).suffix.lower()
    code_exts = {".py", ".js", ".ts", ".tsx", ".java", ".go", ".rs", ".cpp",
                 ".c", ".cs", ".kt", ".rb", ".php", ".scala", ".yml", ".swift", ".md"}
    return chunk_by_lines if ext in code_exts else chunk_by_words

# ---------- Inline UI ----------
@app.route("/", methods=["GET"])
def root():
    return send_from_directory(app.static_folder, "index.html")

# ---------- APIs ----------
@app.route("/index_file", methods=["POST"])
def index_file():
    try:
        f = request.files.get("file")
        if not f:
            return jsonify({"status": "error", "detail": "no file"}), 400

        project_id = str(uuid.uuid4())
        raw_bytes = f.read()

        if f.filename.lower().endswith(".zip"):
            docs, ids, metas = [], [], []
            with zipfile.ZipFile(io.BytesIO(raw_bytes)) as z:
                for name in z.namelist():
                    if name.endswith("/") or name.endswith("\\"):
                        continue
                    with z.open(name) as inner:
                        content = inner.read().decode("utf-8", errors="ignore")
                    chunker = choose_chunker(name)
                    chunks = chunker(content)
                    for i, chunk in enumerate(chunks):
                        docs.append(chunk)
                        ids.append(f"{project_id}:{name}:{i}")
                        metas.append({
                            "project_id": project_id,
                            "filename": name.split("/")[-1],
                            "path": name,
                            "chunk": i
                        })
            if docs:
                collection.add(documents=docs, ids=ids, metadatas=metas)

            return jsonify({
                "status": "ok",
                "project_id": project_id,
                "kind": "zip",
                "filename": f.filename,
                "files_indexed": len({m["path"] for m in metas}),
                "chunks": len(docs)
            })

        # Single-file path
        content = raw_bytes.decode("utf-8", errors="ignore")
        chunker = choose_chunker(f.filename)
        chunks = chunker(content)

        ids = [f"{project_id}:{f.filename}:{i}" for i in range(len(chunks))]
        metas = [{
            "project_id": project_id,
            "filename": f.filename,
            "path": f.filename,
            "chunk": i
        } for i in range(len(chunks))]

        if chunks:
            collection.add(documents=chunks, ids=ids, metadatas=metas)

        return jsonify({
            "status": "ok",
            "project_id": project_id,
            "kind": "file",
            "filename": f.filename,
            "files_indexed": 1,
            "chunks": len(chunks)
        })

    except Exception as e:
        import traceback; traceback.print_exc()
        return jsonify({"status": "error", "detail": str(e)}), 500

@app.route("/index", methods=["POST"])
def index_doc():
    data = request.get_json(force=True, silent=True) or {}
    text = data.get("text", "")
    if not text:
        return jsonify({"status": "error", "detail": "empty text"}), 400
    doc_id = data.get("id") or str(uuid.uuid4())
    collection.add(documents=[text], ids=[doc_id])
    return jsonify({"status": "ok", "indexed_id": doc_id})

@app.route("/query", methods=["POST"])
def query():
    data = request.get_json(force=True, silent=True) or {}
    question = data.get("question", "")
    k = int(data.get("k", 4)) or 4

    results = collection.query(query_texts=[question], n_results=k, include=["documents"])
    docs = (results.get("documents") or [[]])[0]

    context = "\n\n---\n\n".join(docs) if docs else ""
    prompt = (
        "If the question pretains to the context, use the context + your general knowledge to answer the question, "
        "if it's completely unrelated to the context, use your general knowledge\n\n"
        f"Context:\n{context}\n\nQuestion: {question}\nAnswer:"
    )

    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        answer = (resp.choices[0].message.content or "").strip()
        return jsonify({"answer": answer, "context_docs": docs})
    except Exception as e:
        import traceback; traceback.print_exc()
        return jsonify({"answer": "", "reason": "openai_error", "error": str(e)[:300]}), 500

# ---------- Entrypoint (local dev) ----------
if __name__ == "__main__":
    # Use: python app.py
    app.run(host="0.0.0.0", port=8000, debug=True)
